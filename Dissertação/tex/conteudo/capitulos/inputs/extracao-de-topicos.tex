\section{Extração de Tópicos}


Os modelos de extração de tópicos foram propostos para simplificar e organizar grandes coleções de documentos. Nesse contexto, um tópico é uma estrutura com valor semântico que formam grupos de palavras que frequentemente ocorrem próximas. Essas palavra ajudam a descrever um documento ou sub-conjunto de documentos e ajudam a entender o tema ou assunto do texto onde essa estrutura está presente.

As técnicas de extração de tópicos são abordagens não-supervisionadas que visam encontrar a estrutura semântica de uma coleção de documentos a qual é latente, isto é, desconhecida. Os modelos de extração de tópicos baseiam-se na premissa de que um documento é produzido a partir de tópicos previamente definidos, os quais se deseja abordar no texto e determinam os termos a sem utilizados em um documento.

O processo de elaboração do documento a partir desses tópicos é chamado de processo generativo ou modelo generativo, o qual é desconhecido porém, pode ser estimado  com base nos termos presentes no documento, aqui chamados de variáveis observáveis. Assim, o processo de extração de tópicos consiste em estimar o modelo generativo que deu origem ao documento.

Obtém-se ao final do processo de extração de tópicos uma representação documento-tópico que atribui um peso para cada tópico em cada documento da coleção e um representação termo-tópico que representa a probabilidade de ocorrência de um termo em um documento dado que o tópico está presente no documento.
% Convencionalmente uma matrix documento-termo, extremamente esparsa, é decomposta em outras duas matrizes, sendo documento-tópico e termo-tópico~\cite{Cheng2013}.

% Entre as principais abordagens da literatura está o \textit{Latent Dirichlet Allocation} (LDA) sendo referenciado em diversos trabalhos e considerado um dos primeiros modelos dessa área e base para outros trabalhos. 


% Essas são técnicas não-supervisionadas, ou seja, os resultados são extraídos a partir da análise dos documentos sem a necessidade de informações extras como 


% -- A maioria dos trabalho enquadram-se em duas duas principais categorias, os modelos não-probabilísticos e os modelos probabilísticos.

\subsection{Modelos Não Probabilísticos}

Nos modelos não-probabilísticos um tópico é um conjunto de termos e seus pesos que indicam o quão significante esses termos são para um assunto. A maioria das técnicas não-probabilísticas baseiam-se em técnicas de fatoração de matrizes, onde a matrix documento-termo é projetada em um espaço com menor dimensionalidade chamado \textit{Latent Semantic Space}. Por exemplo, o \textit{Latente Semantic Indexing} (LSI) usa a técnica chamada \textit{Singular Value Decomposition} (SVD) para encontrar padrões no relacionamento entre assuntos e termos em uma coleção de texto não estruturada. Entretanto, esse método não fornecem uma interpretação para elementos com valores negativos~\cite{Cheng2013}. % Trocar essa referência do Cheng2013 pela que ele usa na seção 2 do trabalho dele.
% Convencionalmente uma matrix documento-termo, extremamente esparsa, é decomposta em outras duas matrizes, sendo documento-tópico e termo-tópico~\cite{Cheng2013}.

% -- NMF
Outro modelo popular é o \textit{Non-Negative Matrix Factorization} (NMF) o qual aborda a extração de tópicos como a fatoração de uma matriz documento-termo $W$, extremamente esparsa em duas matrizes não negativas $Z$ e $A$, tal que a resultante de $ZA$ é uma aproximação da matriz $W$ original.  $A$ corresponde a matriz documento-tópico e possui dimensão $k \times m$. $Z$ corresponde a matriz termo-tópico e possui dimensão $n \times k$ onde $n$ é o número de termos, $m$ é o número de documentos da coleção e $k$ é a quantidade de tópicos a serem extraídos.  Diferente do LSI, no processo de fatoração apenas operações aditivas são permitidas, o que garante que as matrizes resultantes não possuem elementos negativos, permitindo uma interpretação mais intuitiva de seus valores. Além disso, o processo de fatoração proporciona a propriedade de \textit{clustering}, ou seja, automaticamente agrupar as colunas da matriz $W$, e dessa forma, oferece a característica interessante de agrupar os documentos da coleção. Uma vez que $k$ é menor que $n$ e $m$, então $A$ e $Z$ são menores que a matriz de entrada, o que resulta em uma versão comprimida da matriz original.


% -> W ~ Ŵ = Z·A
% -> Z·A = Ŵ ~ W

% -- Onde é utilizado


\subsection{Modelos Probabilísticos}

Os modelos probabilísticos utilizam um modelo generativo probabilístico para descobrir os tópicos. Consideram os documentos como uma mistura de tópicos e um tópico como uma distribuição probabilística sobre os termos.
% falar em algum ponto sobre o problema das matrizes esparsas
O PLSA foi um dos primeiros a estender o modelo LSA e formalizar a extração de tópicos probabilísticos. De maneira similar ao LSA, o esse modelo decompõe uma matriz esparsa a fim de reduzir a dimensionalidade. O PLSA cria um modelo estatístico chamado \textit{aspect model} que associa os tópicos as variáveis observáveis atribuindo probabilidades às ligações entre os tópicos e os documentos e entre as palavras e os tópicos. Assim, em comparação ao LSA, é considerado uma método mais robusto por proporcionar uma interpretação probabilística. Por outro lado, esse modelo apresenta desvantagens como o número de parâmetros do modelo que cresce linearmente com o número de documentos da coleção que pode ocasionar \textit{overfitting}. Além disso, não permite calcular as probabilidades de um novo documento acrescentado após a criação da modelo.  % -- E o Expectation Maximization?


A fim de contornar esses problemas, o LDA estende o modelo PLSA incorporando um modelo generativo onde os cada tópico obedece à distribuição multivariada de \textit{Dirichlet} o que o torna menos propenso ao \textit{overfitting} e capaz de inferir tópicos a documentos ainda não observados. É referenciado na literatura como estado da arte sobre modelos probabilísticos de extração de tópicos e influencia uma grande quantidade de trabalhos, tornando-se base para novos modelos.

Os modelos de extração de tópicos foram inicialmente propostos para utilização em mineração texto onde são empregados na redução de dimensionalidade, extração de informações em textos, bem como na organização e recuperação de documentos, sendo utilizados para mensurar a relevância de um termo ou conjunto de termos para determinado assunto ou documento. Visto a popularidade nessas tarefas e flexibilidade dos modelos, logo notou-se sua utilidade em outros tipos de dados com atributos discretos como imagens, grafos e genética. 



























