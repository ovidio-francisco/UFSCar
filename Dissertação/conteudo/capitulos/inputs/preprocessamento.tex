\subsection{Pré-processamento de Textos}


% Palavras como artigos, preposições, pronomes, verbos de estado\footnote{Apresentam uma situação inativa, onde o verbo não expressa uma alteração, mas apenas uma propriedade ou condição dos envolvidos.}. Trata-se também como \textit{stop words} as palavras de uso muito frequente dentro de um determinado domínio as quais não são capazes de discriminar textos, portanto também não devem fazer parte dos atributos~\cite{Rezende2003}. 





% A principal diferença entre os processos de Mineração de Textos e os processos de Mineração de Dados é a etapa de pré-processamento, a estrutura os textos em um formato mais adequado para seu processamento em sistemas computacionais. 




A etapa de preprocessamento refere-se ao processo em que o texto é padronizado e passa por seleção e transformação de seus atributos com finalidade de reduzir sua dimensionalidade mantendo seus elementos mais significantes.
Inicialmente, visto a diversidade de formatos de documentos digitais como pdf docx e odt, o texto desses arquivos é extraído e convertido em texto plano, sem formatação.

Considerando textos com alta dimensionalidade, os termos menos significativos são removidos.
\textit{stop word} são palavras pouco relevantes que não contribuem para a distinção do texto em tópicos ou categorias podem ser removidas, como artigos, preposições, pronomes, verbos de estado\footnote{Apresentam uma situação inativa, onde o verbo não expressa uma alteração, mas apenas uma propriedade ou condição dos envolvidos.}. Trata-se também como \textit{stop words} as palavras de uso muito frequente dentro de um determinado domínio não são capazes de discriminar documentos e também não devem fazer parte dos atributos. A eliminação das \textit{stop words} é feita com base em um conjunto de palavras conhecido como \textit{stoplist}.

Outra forma utilizada para seleção de termos é avaliar a importância de cada termo por meio de medidas estatísticas, como o TF (\textit{term frequency}) e DF (document frequency). O método proposto em~\cite{Luhn1958} é uma técnica baseada na Lei de Zipf~\cite{zipf1932} também conhecida como Princípio do Menor Esforço, em que computando-se a frequência das palavras de um texto, e criando-se seu histograma em ordem decrescente, observa-se a chamada Curva de Zipf, na qual o $k$-ésimo termo mais comum ocorre com frequência inversamente proporcional a $k$. Os termos com alta frequência são considerados pouco relevantes por serem comuns à grande maioria dos documentos, enquanto termos mais raros não possuem caráter discriminatório suficiente. Assim, é possível estabelecer pontos de corte nos extremos da curva, a fim de manter termos com frequência intermediária, os quais são os mais representativos do documento~\cite{Maracini2010}. Na Figura~\ref{fig:luhn} é ilustrada a distribuição do termos mais relevantes em um documento e a curva de Zipf com dois cortes nas extremidades.


  \begin{figure}[!h]
	  \centering
	  \includegraphics[width=0.85\textwidth]{conteudo/capitulos/figs/luhn2.png}
	  \caption{A curva de Zipf e os cortes de Luhn~\cite{Soares2008}.}
	  \label{fig:luhn}
  \end{figure}



As palavras não removidas na seleção de termos passam ainda por um processo conhecido como \textit{stemming}.
A radicalização ou \textit{stemming} é a redução das variações de uma palavra ao seu provável radical ou stem a fim de associar palavras semelhantes e diminuir a dimensionalidade da representação do texto.
Nesse processo, as palavras são reduzidas ao seu provável radical ou \textit{stem}, a fim de se associar palavras semelhantes e diminuir a dimensionalidade da representação do texto. Por exemplo, os termos ``\textit{agenda}'', ``\textit{agendamento}'' e ``\textit{agendar}'' dever ser todas reduzidas ao seu radical em comum ``\textit{agend}''. Com isso, a dimensionalidade é diminuída e tem-se um texto formado apenas por morfemas\footnote{Em Morfologia, um morfema é a menor unidade capaz de expressar significado.} com maior significância.  
% 
% O algoritmo de Porter, proposto por Martin Porter em 1980 é amplamente utilizado em sistemas que processam texto na língua inglesa e frequentemente eficaz na remoção de sufixos. Por outro lado, insuficiente para outros idiomas, uma vez que, seu mecanismo é altamente dependente do idioma inglês.
%

Em geral, algoritmos de \textit{stemming} dependem do uso adequado da ortografia da língua em questão, inclusive com acentuação correta, sendo em alguns casos recomendado o uso de corretores automáticos na fase de pré-processamento. A língua portuguesa particularmente apresenta algumas dificuldades, na elaboração de algoritmos de \textit{stemming}, das quais destacam-se o número elevado exceções e homófagos; palavras com mudanças no radical morfológico; nomes próprios que não podem ser radicalizados e frequência de termos estrangeiros.  É possível identificar alguns erros apresentados pelos algoritmos de \textit{stemming} que reduzem a qualidade os resultados da mineração de texto, como \textit{oversteamming:} quando o algoritmo remove parte do radical e \textit{understeamming:} quando o algoritmo não remove totalmente o sufixo.

O uso de \textit{stemming}, de uma maneira geral, pode trazer algumas desvantagens das como a perda de contexto, pois palavras com sentidos diferentes podem resultar no mesmo radical, aumentando assim a quantidade de homônimos e a perca da precisão que diminui a variedade de palavras causando certa perda de informação. Contudo, eventuais perdas de informação por \textit{stemming} não causam grandes impactos sobre a eficiência de algoritmos de text mining e seu uso se justifica pela redução da dimensionalidade da base de textos.



