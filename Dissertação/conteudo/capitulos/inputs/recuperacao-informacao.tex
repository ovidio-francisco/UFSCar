
\section{Modelos de Recuperação de Informação}

% Necessidade de encontrar informação

Devido à popularização dos computadores e a grande disponibilidade de documentos em formato digital, em especial na \textit{web}, a área da Recuperação de Informação (RI) tem recebido atenção de pesquisadores nas últimas décadas. Recuperação de Informação é a área da computação que envolve a aplicação de métodos computacionais no tratamento e busca de informação em bases de dados não estruturados, usualmente grandes coleções de documentos textuais armazenados em dispositivos eletrônicos. De fato, não há dados completamente não estruturados ao se considerar a estrutura linguística latente em documentos textuais. O termo ``não estruturado'' se refere a dados que não oferecem uma estrutura clara para sistemas computadorizados~\cite{Manning2008, Gutierrez2016}.
% , a exemplo de documentos textuais

% Tratamento == Classificação e Agrupamento?

A tarefa central da recuperação de informação é encontrar informações de interesse dos usuários e exibí-las. 
% Essa necessidade motiva o desenvolvimento de sistemas de recuperação de informação (SRI).
Nesses sistemas o usuário expressa sua necessidade por meio da formulação de uma consulta, usualmente composta por um conjunto de palavras-chave. Então, o sistema apresenta os resultados da busca, frequentemente documentos, em ordem de relevância com a consulta.  % TODO: Melhorar


% \subsection{Modelos de Recuperação de Informação}

Um modelo de recuperação de informação deve criar representações de documentos e consultas a fim de predizer a necessidade expressa nos termos da consulta. Com base na entrada do usuário esses modelos buscam por documentos similares aos termos da consulta. Segue abaixo a descrição dos três modelos clássicos para recuperação de informação.

\subsection{Modelo Booleano}

O modelo booleano ou modelo lógico foi um dos primeiros modelos aplicados à Recuperação Informação sendo utilizado a partir de 1960. Nesse modelo uma consulta é considerada uma sequencia de termos conectador por operadores lógicos como AND, OR e NOT. Como resultado, classifica cada documento como relevante ou não relevante à consulta, sem gradação de relevância. Esses operadores lógicos podem ser manipulados por usuários com algum conhecimento em álgebra booleana para aumentar a quantidade de resultados ou restringí-la.

Uma desvantagem desse modelo é que não é possível medir a relevância de um documento em relação a consultado do usuário, devido a essa limitação não há informação que permita a ordenação dos resultados, que é uma característica esperada para muitos sistemas de RI.
Já as vantagens desse modelo são a facilidade de implementação e a possibilidade de usuários experientes usarem os operadores lógicos como uma forma de controle sobre os resultados da busca. Por outro lado, para usuários inexperientes isso pode ser considerado uma desvantagem, uma vez que o uso de expressões lógicas não é intuitivo. Apesar dos problemas apresentados, visto sua simplicidade, esse modelo foi largamente utilizado em sistemas comerciais. 

% Falar do Booleano Estendido???


\subsection{Modelo Espaço Vetorial}
\label{subsec:modeloespacovetorial}

Uma das formas mais comuns para representação textual é conhecida como Modelo Espaço Vetorial (\textit{Vectorial Space Model} - VSM), onde os documentos e consultas são representados como vetores em um espaço Euclidiano $m$-dimensional em que cada termo extraído da coleção é representado por uma dimensão~\cite{Rezende2003}. 
% 
Considera-se que um documento pode ser representado pelo seu conjunto de termos, onde cada termo $t_i$ de um documento $d_j$ associa-se um peso $w_{ij}\geq0$ que indica a importância desse termo no documento. 
%
De forma similar, para uma consulta $q$, associa-se um peso $w_{i,q}$ a cada termo consulta. 
%
Assim o vetor associado ao documento $d_j$ é dado por $\vec{d}_{j} = (w_{j,1}, w_{j,2}, ..., w_{j,p})$ 
%
e o vetor associado a consulta $q$ é dado por $\vec{q} = (w_{q,1}, w_{q,2}, ..., w_{q,l})$.
%
% -- Movido para "Medidas de Proximidade " ↓↓↓↓
No modelo vetorial, a similidade entre um documento $d_j$ e uma consulta $q$ é calculada pela correlação entre os vetores $\vec{d_j}$ e $\vec{q}$, a qual pode ser medida pelo cosseno (Equação~\ref{equ:cosine}) do ângulo entre esses vetores, conforme mostrado adiante na Seção~\ref{subsec:MedidasProximidade}. 



% \begin{equation}
% sim(d_j, q) = \frac{ \vec{d_j} \bullet \vec{q} }
                   % { |\vec{d_j}| \times | \vec{q}|}
            % = \frac{ \sum_{i=1}^{t} w_{i,j} \cdot w_{i,q} }
                   % { \sqrt{\sum_{i=1}^{t} w_{i,j}^2} \times \sqrt{\sum_{i=1}^{t} w_{i,q}^2 } }                   \label{equ:cosseno-doc-consulta}		                   
% \end{equation} 


% \begin{equation}
	% sim(d_j, q) = cosseno(d_j, q) 
% 
% = \frac{ \vec{d_j} \bullet \vec{q} } { |\vec{d_j}| \times | \vec{q}|}
% 
% \frac{ \vec{d_j} \bullet \vec{q} }
				   % { |\vec{d_j}| \times | \vec{q}|}
% = \frac{ \sum_{i=1}^{t} w_{i,j} \cdot w_{i,q} }
	   % { \sqrt{\sum_{i=1}^{t} w_{i,j}^2} \times \sqrt{\sum_{i=1}^{t} w_{i,q}^2 } }
% 
% \label{equ:cosseno-doc-consulta}		                   
% \end{equation} 

% Valores de cosseno próximos a 0 indicam um ângulo próximo a 90º entre $\vec{d_j}$ e $\vec{q}$, ou seja, o documento $d_j$ compartilha poucos termos com a consulta $q$, enquanto valores próximos a 1 indicam um ângulo próximo a 0º, ou seja, $d_j$ e $q$ compartilham termos e são similares~\cite{Tan2005,Feldman2006}.



Avaliar a relevância de um documento sob uma consulta é fundamental para os modelos de RI. Para isso pode-se utilizar medidas estatísticas simples como a frequência do termo, conhecida como TF (do inglês \textit{Term Frequency}) e a frequência de documentos, conhecida como DF (do inglês \textit{Document Frequency}). A frequência do termo indica o número de vezes que um termo ocorre na coleção de documentos. A frequência de documentos, indica o número de documentos que contém ao menos uma ocorrência de um determinado termo. Considera-se que os termos que ocorrem frequentemente em muitos documentos, em geral, não trazem informações úteis para discriminar a relevância dos documentos, então, a fim de diminuir o peso de termos altamente frequentes, usa-se o fator IDF (\textit{Inverted Document Frequency}), que é o inverso da número de documentos que contem um termo. O IDF é a medida de informação que um termo fornece com base em quão raro ou comum esse termo é para a coleção. Seja $n$ o número de documentos de uma coleção e $N_i$ o número de documentos onde o termo $t_i$ ocorre, o cálculo de IDF é dado por: 

	\begin{equation}
		IDF(t_i) = log\frac{n}{N_i}~.
		\label{equ:IDF}
	\end{equation}

Entre as medidas mais populares para ranqueamento de buscas está a TF-IDF (\textit{Term Frequency-Inverted Document Frequency}) que pondera a frequência de um termo em um documento com sua frequência na coleção total de documentos. Assim, a relevância de um termo para um documento é dada por:

\begin{equation}
	w_{i,j} = freq_{i,j} \cdot IDF(t_i)~,
\end{equation}


\noindent
onde $freq_{i,j}$ é a frequência do termo $t_i$ no documento $d_j$. A medida TF-IDF atribui valores altos para termos que ocorrem frequentemente em um documentos, e valores menores para termos que ocorrem poucas vezes em um documento ou em muitos documentos da coleção. A ideia da medida TF-IDF e quantificar a importância de um termo em um documento com base em sua frequência no próprio documento e sua distribuição ao longo da coleção de documentos~\cite{Croft2009,Salton1988,Shamsinejadbabki2012,Salton:1994}.


Uma vez que o modelo, por meio da Equação~\ref{equ:cosine}, calcula a similaridade entre os documentos e a consulta do usuário, é possível ranquear os resultados por ordem de relevância. Além disso, sua relativa simplicidade e flexibilidade, favorecem a aplicação desse modelo em sistemas de Recuperação de Informação~\cite{Tan2005,Croft2009,Manning2008}.

% ->-----------------------------------------------------------------------


\subsection{Modelo Probabilístico}

 
O modelo probabilístico é baseado no princípio da ordenação probabilística (\textit{Probability Ranking Principle}) onde dada um consulta $q$ e um documento $d_j$ relevante a $q$, o modelo tenta estimar a probabilidade do usuário encontrar o documento $d_j$. O modelo assume que para uma consulta $q$ há um conjunto de documentos $R_q$ que contém exatamente os documentos relevantes e nenhum outro, sendo este um conjunto resposta ideal que maximiza a probabilidade do usuário encontrar um documento $d_j$ relevante a $q$. 

Seja $\overline{R_q}$ o complemento de $R$ de forma que $\overline{R_q}$ contém todos os documentos não relevantes à consulta $q$. Seja $P(R_q|d_j)$ a probabilidade do documento $d_j$ ser relevante à consulta $q$ e $P(\overline{R_q}|d_j)$ a probabilidade de $d_j$ não ser relevante à $q$. A similaridade entre um documento $d_j$ e uma consulta $q$ é definida por:





\begin{equation}
	sim(d_j, q) = \frac{P(R_q|dj)}{P(\overline{R_q}|dj)} 
	\label{equ:simprob}
\end{equation}


A fim de obter-se uma estimativa numérica das probabilidades, o modelo assume o documento como uma combinação de palavras e seus pesos aos quais atribui-se valores binários que indicam a presença ou ausência de um termo, isto é, $w_{ij} \in \{0,1\}$ e $w_{iq} \in \{0,1\}$. Seja $p_i = P(t_i|R_q)$ a probabilidade do termo $k_i$ ocorrer em um documento relevante à consulta $q$, e $s_i    = P(k_i|\overline{R_q})$ a probabilidade do termo $k_i$ estar presente em um documento não relevante. 
Seja ainda $\prod_{i:d_i=1}$ o produto dos termos com valor 1. 
Então, pode-se calcular:

\begin{equation}
	sim(d_j, q) = 	
	\prod_{i:d_i=1} \frac{p_i}{s_i} 
	\cdot
	\prod_{i:d_i=0} \frac{1 - p_i}{1 - s_i}~,
	\label{equ:simprob-numeric}
\end{equation}


\noindent
onde $\prod_{i:d_i=1}$ significa o produto dos termos com valor 1.\\


%
%
O modelo também supõe que os termos ocorrem independentemente no documento, ou seja, a ocorrência de um termo não influencia a ocorrência de outro. 
Partindo dessas suposições, a Equação~\ref{equ:simprob-numeric} passa por transformações que incluem aplicação da regra de Bayes e simplificações matemáticas, e chega-se a Equação~\ref{equ:robertson} conhecida como equação de Robertson-Spark Jones a qual é considerada a expressão clássica para ranqueamento no modelo probabilístico. Detalhes da dedução dessa equação podem ser encontrados em~\cite{Croft2009, Manning2008, Rijsbergen1979},



\begin{equation}
	sim(d_j,q) = \sum_{i=1}^{t} w_{i,j} \cdot w_{i,q}  \cdot \sigma_{i/R}~,
	\label{equ:robertson}
\end{equation}



\noindent
onde $t$ é o número total de termos da coleção e 



\begin{equation}
	\sigma_{i/R} = \log \frac{p_i}{1-p_i} + \log \frac{1-s_i}{s_i}~.
\end{equation} 


Esse modelo tem com principal desvantagem a necessidade de estimar a separação inicial entre $R_q$ e $\overline{R_q}$, pois não se conhece inicialmente o conjunto dos documentos relevantes a uma consulta, o qual deve ser aprimorado por meio de interações com o usuário. Além disso, o modelo não leva em consideração a frequência dos termos na indexação do documento. O modelo apresenta como vantagem a característica de atribuir probabilidades as similaridades entre documentos e consultas, o que permite ranquear dos resultados por ordem de relevância. 












