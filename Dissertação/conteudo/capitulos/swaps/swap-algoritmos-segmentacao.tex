

















































% -------------------------------------------------------------------------------	

https://www.google.com.br/search?client=firefox-b-ab&dcr=0&biw=1366&bih=670&tbm=isch&sa=1&ei=RGGQWt-FEoiOwgSN-anAAg&q=matrix+similarity&oq=matrix+similarity&gs_l=psy-ab.3..0i30k1j0i8i30k1l4j0i24k1l5.12020.37176.0.37476.23.21.0.0.0.0.138.2184.4j16.21.0....0...1c.1.64.psy-ab..4.18.2002.0..0j0i67k1j0i10k1j0i13k1j0i8i13i30k1.156.T7IoINvSxsw#imgrc=OkvVC-pZIjQmLM:


https://www.researchgate.net/figure/Similarity-matrix-for-a-selection-of-objects-in-the-feature-dataset-Colour-scale_fig3_265418378

https://github.com/alunos-mestrado-emap/modelagem-assuntos-artigos/issues/2

% -------------------------------------------------------------------------------	



% Finalmente, com base na matriz de \textit{ranking}, o C99 utiliza um método de \textit{clustering} baseado no algoritmo \textit{DotPloting}~\cite{Reynar1998} que usa regiões com maior densidade em uma matriz de similaridades para determinar como os segmentos estão distribuídos. Um segmento é definido por duas sentenças $i$ e $j$ que representam uma região quadrada ao longo da diagonal da matriz. Calcula-se a densidade dessa região como mostrado na Equação~\ref{equ:densidade-c99}. Seja $s_{i,j}$ a somatória dos \textit{rakings} de um segmento e $a_{i,j}$ sua área interior. Seja $B = \{b1,...,b_m\}$ a lista de $m$ segmentos e $s_k$ e $a_k$ são a somatória dos valores dos rankings e a área de um segmento $k$ em $B$. Então, a densidade é computada por: 







Seja $B = \{b1,...,b_m\}$ a lista de $m$ segmentos e $s_k$ e $a_k$ são a somatória dos valores dos rankings e a área de um segmento $k$ em $B$. Então, a densidade é computada por: 



Seja $s_{i,j}$ a somatória dos \textit{rakings} de um segmento 
Seja $s_{i,j}$ a somatória dos \textit{rakings} de um segmento e $a_{i,j}$ a área quadrada que contém o segmento. 





% --> % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
Papers falando da densidade do C99

file:///ext4Data/UFSCar/papers/Segmentação/Clássicos/Advances in domain independent linear text segmentation.pdf
file:///ext4Data/UFSCar/papers/Segmentação/recentes/A Study on Statistical Generation of a Hierarchical Structure of Topic-information for Multi-documents.pdf
file:///ext4Data/UFSCar/papers/Segmentação/An analysis of quantitative aspects in the evaluation of thematic segmentation algorithms.pdf
file:///ext4Data/UFSCar/papers/Segmentação/COMPARATIVE ANALYSIS OF C99 AND TOPICTILING TEXT SEGMENTATION ALGORITHMS.pdf
file:///ext4Data/UFSCar/papers/Segmentação/Fuzzy Implementation of proposed hybrid algorithm using Topic Tilling and C99 for Text Segmentation.pdf
% --> % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
































O objetivo final no modelo é simultaneamente maximizar a dissimilaridade entre partições e maximizar
encontrar múltiplas partições. 





% O \textit{MinCutSeg} aborda a segmentação textual como um problema de particionamento de grafo, em que cada nó representa um sentença e os pesos das arestas representam a similaridade entre duas sentenças. Nessa abordagem, a segmentação textual corresponde ao particionamento do grafo que otimiza o critério de corte normalizado (\textit{normalized-cut criterion}) proposto por ~\cite{Shi2000} a qual foi desenvolvida para segmentação de imagens estáticas, porém, nesse contexto aproveita a restrição de linearidade dos textos para segmentação textual.

O \textit{MinCutSeg} visa minimizar o corte definido pela somatória dos de modo a particionar $G$ em dois grafos disjuntos


as arestas que ligam A à B

minimizar o corte que particiona $G$ em dois grafos disjuntos $A$ e $B$ com dissimilaridade máxima. 



que otimiza o critério de corte normalizado (\textit{normalized-cut criterion}) proposto por ~\cite{Shi2000}. Esse critério foi desenvolvido para segmentação de imagens estáticas, porém, nesse contexto aproveita a restrição de linearidade dos textos para segmentação textual.



. O 

% Similar a abordagem do C99, o MinCutSeg vê o texto como uma matrix 



utiliza a técnica \textit{normalized-cut criterion}~\cite{Shi2000} a qual foi desenvolvida para segmentação de imagens estáticas, porém, nesse contexto aproveita a restrição de linearidade dos textos para segmentação textual.


Nesse trabalho, a segmentação textual corresponde ao particionamento do grafo que otimiza o "critério de corte normalizado"~\cite{Shi2000}.



divisão do grafo que otimiza o h



de acordo com critério proposto por~\cite{Shi2000).

% O \textit{MinCutSeg} aborda a segmentação textual como um problema de particionamento de grafo, em que cada nó representa um sentença e os pesos das arestas representam a similaridade entre duas sentenças. Essa abordagem utiliza a técnica \textit{normalized-cut criterion}~\cite{Shi2000} a qual foi desenvolvida para segmentação de imagens estáticas, porém, nesse contexto aproveita a restrição de linearidade dos textos para segmentação textual.




% a maior probabilidade ...



%onde $w_j^i$ é a j-ésima palavra no segmento $S_i$.

%onde $P(w_j^i|S_i)$ é a probabilidade da palavra $w_j^i$ ocorrer no segmento $S_i$, a qual pode ser calculada como:


%A suposição de que os segmentos são independentes entre si 


Normalized cuts and image segmentation








% ==========  MinCut  ==========



Similar a abordagem do C99, o MinCutSeg vê o texto como uma matrix 
















1 - TextSeg
2 - MinCut
3 - BayesSeg


Lexical cohesion e.g., 
	- Utiyama and Isahara,     2001; {TextSeg}
	- Galley et al.            2003; {LCSeg}
	- Malioutov and Barzilay,  2006  {}








MinCutSeg segmenter (Malioutov & Barzilay 2006)




Assim, cada elemento é comparado com seus vizinhos dentro de uma região denominada máscara.
Nesse capítulo, inicialmente serão introduzidos alguns conceitos comuns 



Embora muitos trabalhos utilizem a coesão léxica do texto, para pequenos segmentos pode não ser confiável,





, em que dado dois blocos de texto $x$ e $y$,

conforme apresentada na , onde dados dois blocos de texto, $x$ e $y$, $f_{x,j}$ é a frequência do termo $j$ em $x$ e $f_{y,j}$ é a frequência do termo $j$ em $y$.

\begin{equation}
	Sim(x,y) = \frac
	{\Sigma_j f_{x,j} \times f_{y,j}}
	{\sqrt{\Sigma_j f^2_{x,j} \times \Sigma f^2_{y,j}}}
	\label{equ:cosine}
\end{equation}




analisa-se o texto circundante a cada candidato a limite.




A partir dos conceitos de coesão léxica, o \textit{TextTiling} foi um dos primeiros algoritmos propostos para segmentação textual. Baseia-se na

A partir desses conceitos, um dos primeiros algoritmos baseados na ideia que um segmento pode ser identificado pela análise das palavras que o compõe foi o \textit{TextTiling}. O \textit{TextTiling} é um algoritmo baseado em janelas deslizantes, em  que, para cada candidato a limite, analisa-se o texto circundante. O \textit{TextTiling} recebe uma lista de candidatos a limite, usualmente finais de parágrafo ou finais de sentenças. Para cada posição candidata são construídos 2 blocos, um contendo sentenças que a precedem e outro com as que a sucedem. O tamanho desses blocos é um parâmetro a ser fornecido ao algoritmo e determina o tamanho mínimo de um segmento. Esse processo é ilustrado na Figura~\ref{fig:TT-slidingwindow}.





% Kosima uniu as tecnicas de SW e CL.
% calcula-se a coesão léxica das palavras contidas na janela. 
% Os algoritmos que se baseiam no cálculo da similaridade entre sentenças, frequentemente o fazem por meio de janelas deslizantes, 

% 

% Os primeiros trabalhos dessa área se apoiam na ideia de que a mudança de assunto em um texto é acompanhada de uma proporcional mudança de vocabulário. Essa ideia, chamada de coesão léxica, sugere que a distribuição das palavras é um forte indicador da estrutura do texto~\cite{Kozima1993}. Demonstrou-se que há uma estreita correlação entre quedas na coesão léxica em janelas de texto e a transição de assuntos. Em seu trabalho, calculou a coesão léxica de uma janela de palavras usando \textit{spreading activation} em uma rede semântica especialmente elaborada para o idioma Inglês. Contudo, a implementação de um algoritmo para outros domínios depende da construção de uma rede adequada. 








% % ==========  Janelas deslizantes  ==========

% % Kosima uniu as tecnicas de SW e CL.
% Para encontrar os segmentos de um texto, alguns dos primeiros algoritmos utilizam a técnica de janelas deslizantes, onde se verifica a frequência dos termos em um fragmento do documento. Inicialmente, estabelece-se a partir do início do texto, um \textit{range} de $w$ termos, chamado janela que em seguida é deslocada em passos de $k$ termos adiante até o final do texto. A cada passo, analisa-se os termos contidos na janela.
% % calcula-se a coesão léxica das palavras contidas na janela. 
% % Os algoritmos que se baseiam no cálculo da similaridade entre sentenças, frequentemente o fazem por meio de janelas deslizantes, 


% %  Coesão léxica como presuposto básico
% % Para encontrar essas posições, 
% Trabalhos anteriores se apoiam na ideia de que a mudança de assunto em um texto é acompanhada de uma proporcional mudança de vocabulário. Essa ideia, chamada de coesão léxica, sugere que a distribuição das palavras é um forte indicador da estrutura do texto~\cite{Kozima1993}. O autor demonstrou que há uma estreita correlação entre quedas na coesão léxica em janelas de texto e a transição de assuntos. Em seu trabalho, calculou a coesão léxica de uma janela de palavras usando \textit{spreading activation} em uma rede semântica especialmente elaborada para o idioma Inglês. Contudo, a implementação de um algoritmo para outros domínios dependia da construção de uma rede adequada. 


