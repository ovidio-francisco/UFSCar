\section{Referencial Teórico}
	\label{sec:referencial}
	
%%%%%%%%%%
% Retomada das Definições
%%%%%%%%%%	
%
% Documento é uma sucessão de assuntos
%%% 
Um documento textual, sobre tudo quando longo, é frequentemente uma sucessão de assuntos. 
%
% Segmentação
%%% 
A segmentação textual ou segmentação topical é a tarefa de dividir um texto mantendo em cada parte um tópico com seu significado completo.
	


%%%%%%%%%%%%%%%
% Unidades de Informação 
%%%%%%%%%%%%%%% 
%
% O texto deve ser divido em unidades que não pode ser dividida entre segmentos 
%%% 
O texto deve ser previamente dividido em unidades de informação, que podem ser palavras, paragrafos e mais usualmente em sentenças. Essas unidades são processadas pelos algoritmos como a menor parte de um segmento, ou seja uma unidade não pode divida, mas deve pertencer integralmente a um segmento.
%
% Exemplos 
%%% 
Por exemplo, algoritmos baseados em janelas deslizantes, avançam uma unidade a cada passo. Da mesma forma, algoritmos baseados em matrizes de similaridade, devem calcular a similaridade entre essas unidades.
%
% Sentaças são mais usuais 
%%% 
Usualmente usa-se sentenças como unidades informação, ou seja, as janelas deslizam uma sentença a cada passo e matrizes de similaridades armazenam as similaridades entre as sentneças do texto.
%
% O ponto entre unidades é um limite 
%%% 
Assim, cada ponto entre duas unidades de informação é considerado um candidato a limite entre segmentos.  
%%%%%%%%%%
% Segmento
%%%%%%%%%%	
Dessa forma, um segmento pode ser visto como uma sucessão de unidades de informação que compartilham o mesmo assunto. 



%%%%%%%%%%
% Coesão léxica como **presuposto básico**
%%%%%%%%%%
Trabalhos anteriores se apoiam na ideia de que a mudança de tópicos em um texto é acompanhada de uma proporcional mudança de vocabulário, essa ideia, chamada de coesão léxica, sugere que a distribuição das palavras é um forte indicador da estrutura do texto. A partir disso, vários algoritmos foram propostos baseados na ideia de que um segmento pode ser identificado e delimitado pela análise das palavras que o compõe~\cite{Galley2003}~\cite{Boguraev2000}.



%, bem como é necessário mensurar suas similaridades. { asunidades de medida}

%%%%%%%%%%
% Porque cosseno
%%%%%%%%%%
Uma vez que a coesão léxica é pressuposto básico da maioria dos algoritmos, o cálculo da similaridade entre unidades de informação (comumente sentenças) é fundamental. Uma medida de similidade frequentemente utilizada é o cosseno, apresentada na Equação~\ref{equ:cosine}, onde $f_{x,j}$ a frequência da palavra $j$ na sentença $x$ e $f_{y,j}$ sendo a frequência da palavra $j$ na sentença $y$.


\begin{equation}
Sim(x,y) = \frac
{\Sigma_j f_{x,j} \times f_{y,j}}
{\sqrt{\Sigma_j f^2_{x,j} \times \Sigma f^2_{y,j}}}
\label{equ:cosine}
\end{equation}


\subsection{Principais algoritmos}
	\label{subsec:principaisalgoritimos}

Entre os principais trabalhos da literatura podemos citar o  \textit{TextTiling}~\cite{Hearst1994} e o \textit{C99}~\cite{Choi2000}.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%              TextTiling                 %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
O \textit{TextTiling} é um algoritmo baseado em janelas deslizantes, onde para cada candidato a limite, analisa-se o texto circundante. Um limite ou quebra de segmento é identificado quando sempre que a similaridade cai abaixo de um limiar.
% \textit{threshold}. %TODO - explicar como se encontra os vales


O \textit{TextTiling} recebe uma lista de candidatos a limite, usualmente finais de parágrafo ou finais de sentenças. Para cada posição candidata são construídos 2 blocos, um contendo sentenças que a precedem e outro com as que a sucedem. O tamanho desses blocos é um parâmetro a ser fornecido ao algoritmo e determina o tamanho mínimo de um segmento.
%
Em seguida, os blocos de texto são representados por vetores que contém as frequências de suas palavras. Então, usa-se cosseno (Equação~\ref{equ:cosine}) para calcular a similaridade entre os blocos adjacentes a cada candidato e identifica-se uma transição entre tópicos pelos vales na curva de dissimilaridade.

%TODO como apresentado na Figura~\ref{fig:curvadedissimilaridade}.


O \textit{TextTiling} possui menor complexidade computacional. Por outro lado, algoritmos mais complexos apresentam acurácia relativamente superior como apresentado em~\cite{Choi2000, Kern2009, Misra2009}.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                  C99                    %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Choi \cite{Choi2000} apresenta um algoritmo baseado em ranking, o \textit{C99}. 
%
Embora muitos trabalhos utilizem matrizes de similaridades, o autor traz obervações.
%
Ele aponta que para pequenos segmentos, o cálculo de suas similaridades não é confiável, pois uma ocorrência adicional de uma palavra causa um impacto que pode alterar significativamente o cálculo da similaridade.
%
Além disso, o estilo da escrita pode não ser constante em todo o texto. Choi sugere que, por exemplo, textos iniciais dedicados a introdução costumam apresentar menor coesão do que trechos dedicados a um tópico específico. Portanto, comparar a similaridade entre trechos de diferentes regiões não é apropriado.
% Complexidade O(n²)
Devido a isso, as similaridades não podem ser comparadas em valores absolutos. Então, o autor contorna esse problema fazendo uso de \textit{rankings} de similaridade para encontrar os segmentos de texto. 


Inicialmente é construída uma matriz que contém as similaridades de todas as unidades de texto. Em seguida, cada valor na matriz de similaridade é substituído por seu ranking local. Onde para cada elemento da matiz, seu \textit{ranking} é o número de elementos vizinhos com valor de similaridade menor que o seu.

% O que é a máscara
Então, para cada elemento delimita-se uma região da matriz, denominada máscara, para comparar com seus vizinhos.
%
Na Figura~\ref{fig:exemplomatrixrank} é apresentado um quadro de dimensões 3~x~3 destacado na matriz de similaridades, que contém os valores $\{0,3; 0,4; 0,4; 0,6; 0,5; 0,2; 0,9; 0,5; 0,7\}$, onde cada elemento da matrix é a similaridade entre duas unidades de informação. Tomando como exemplo o elemento com valor $0,5$, a mesma posição na matriz de \textit{ranks} terá o valor $4$, pois esse é o número de vizinhos com valores inferiores a $0,5$ dentro do quadro analisado na matriz de similaridades. 


  \begin{figure}[!h]

	\centering
	\includegraphics[width=0.45\textwidth]{exemplo-matrix-rank-noborder.jpg}
	\caption{Exemplo de construção de uma matriz de rank.~\cite{Choi2000}}
	\label{fig:exemplomatrixrank}

  \end{figure}



Finalmente, utiliza um método de divisão por \textit{clustering} baseado no algoritmo de maximização de Reynar~\cite{Reynar1998} para identificar os limites entre os segmentos. 

\subsection{Medidas de Avaliação}

%%%%%%%%%%%%%%%
% Medidas de avaliação tradicionais 
%%%%%%%%%%%%%%%
%
% Utilizadas em RI e Classificação 
%%% 
As medidas de avaliação tradicionais como acurácia e precisão são usadas em recuperação de informação e classificação automática para medir o desempenho de modelos de classificação e predição.
%
% Baseadas em Matriz de Confusão 
%%% 
Essas medidas são baseadas na comparação dos valores produzidos por uma hipótese com os valores reais. Uma matriz de confusão é uma tabela que permite a visualização do desempenho de um algoritmo. Na Tabela~\ref{tab:matrizconfusao} é apresentado a matriz de confusão para duas classes (Positivo e Negativo).


\begin{table}[!h]
	\centering
	
	\begin{tabular}{|c|c|c|}
		\hline
		                & Predição Positiva         & Predição Negativa        \\ \hline
		Positivo real   & VP (Verdadeiro Positivo)  & FN (Falso Negativo)      \\ \hline
		Negativo real   & FP (Falso Positivo)       & VN (Verdadeiro Negativo) \\ \hline
	
	\end{tabular}
	
	\caption{Matriz de confusão.}
	\label{tab:matrizconfusao}

\end{table}


%%%%%%%%%%
%	Avaliações baseadas em hits 
%%%%%%%%%%
Essas medidas de avaliação tentam computar os erros do algoritmo, isto é, falsos positivos e falsos negativos, a fim de calcular sua eficiência. 
%
% Falso Positivo 
%%%
No contexo de segmentação textual, um falso positivo é um limite identificado pelo algoritmo que não corresponde a nenhum limite na segmentação de referência, ou seja, o algoritmo indicou que em determinado ponto entre duas sentenças há uma quebra de segmento, mas que na segmentação de referência, no mesmo ponto, não há. 
%
% Falso Negativo 
%%% 
De maneira semelhante, um falso negativo é quando o algoritmo não identifica um limite existente na segmentação de referência, ou seja, em determnado ponto entre duas sentenças, há na segmentação de referência um limite entre segmento, contudo, o algoritmo não o identificou.
%
% Verdadeiro Positivo 
%%% 
Um verdadeiro positivo é um ponto no texto indicado pelo algoritmo e pela segmentação de referência como uma quebra de segmentos, ou seja, o algoritmo e a referência concordam que em determinado ponto há uma transição de assunto.
%
% O Verdadeiro Negativo, que não existe 
%%%
Na avaliação de segmentadores, não há o conceito de verdadeiro negativo. Este seria um ponto no texto indicado pelo algoritmo e pela segmentação de referência onde não há uma quebra de segmentos. Uma vez que os algoritmos apenas indicam onde há um limite, essa medida não é necessária. % Não há ou não e necessário?

Nesse sentido, 
%
a precisão, que é a proporção de limites corretamente identificados pelo algoritmo, e 
%
a revocação, que é a proporção de limites verdadeiros que foram identificados pelo algoritmo,
%
trazem alguns problemas na avaliação de segmentadores automáticos.
 	
	
Conforme o algoritmo aponta mais segmentos no texto, este tende a melhorar a revocação e ao mesmo tempo, reduzir a precisão. Esse problema de avaliação pode ser contornado utilizado a medida $F^1$ que é uma média harmônica entre precisão e revocação onde ambas tem a o mesmo peso. 

Além dessas medidas, que consideram apenas se um segmento foi corretamente definido, pode-se também considerar a distância entre o segmento extraído automaticamente e o segmento de referência~\cite{Kern2009}.

% As medidas de avaliação tradicionais baseiam se na contagem de acertos. Quando um fim de segmento extraído automaticamente coincide com o limite de referência, têm-se um acerto.

Na Figura~\ref{fig:exemplosegmentacaozoom} é apresentado um exemplo com duas segmentações extraídas automaticamente e uma referência. Na Figura~\ref{fig:exemplosegmentacao}, em ambos os casos não há nenhum verdadeiro positivo, o que implica em zero para os valores de precisão, acurácia, e revocação, embora a segunda hipótese possa ser considerada superior à primeira se levado em conta a proximidade dos limites.



  \begin{figure}[!h]

	\centering
	\includegraphics[width=0.47\textwidth]{windiffzoom.jpg}
	\caption{Exemplos de \textit{near missing} e falso positivo puro. Os blocos indicam uma unidade de informação e as linha verticais representam os limites entre segmentos de texto representando um tópico do texto. }
	\label{fig:exemplosegmentacaozoom}

  \end{figure}
  
  \begin{figure}[!h]

	\centering
	\includegraphics[width=0.47\textwidth]{windiff.jpg}
	\caption{
	Exemplo de duas segmentações hipotéticas em comparação a uma ideal. 
	}
	\label{fig:exemplosegmentacao}

  \end{figure}
  

Considerando o conceito de \textit{near misses}, algumas soluções foram propostas. As medidas de avaliação mais utilizadas são:

\begin{enumerate}

	\item Em~\cite{Beeferman1999} é apresentada uma medida denominada P$_k$, aqual atribui valores parciais a \textit{near misses}, ou seja, limites sempre receberão um peso proporcional à sua proximidade, desde que dentro de um janela de tamanho~$k$.
%
Para isso, esse método move uma janela de tamanho $k$ e a cada posição verifica se o início e o final da janela estão ou não dentro do mesmo segmento e penaliza o algoritmo em caso de discrepância. Ou seja, dado duas palavras de distancia $k$, uma discrepância é computada quando o algoritmo e a referência não concordam se as palavras estão ou não no mesmo segmento.

O valor de $k$ é calculado como a metade da média dos comprimentos dos segmentos reais. Como resultado, é retornado a contagem de discrepâncias divida pelo quantidade de segmentações analisadas. 

P$_k$ é uma medida de dissimilaridade entre as segmentações e pode ser interpretada como a probabilidade de duas sentenças extraídas aleatoriamente pertencerem ao mesmo segmento.

\item \textit{WindowDiff}. Pevzner~\cite{Pevzner2002} aponta problemas na avaliação mais tradicional, P$_k$~\cite{Beeferman1999}. Eles apontam que esse método penaliza demasiadamente os falsos negativos em relação aos falsos positivos e a \textit{near misses}, além disso, desconsidera o tamanho dos segmentos. Como solução, propõem um método, que traz duas diferenças principais: a dobra da penalidade para os falsos positivos a fim de diminuir o problema da subestimação dessa medida e, diferente de P$_k$, ao mover a janela pelo texto, penaliza-se o algoritmo sempre que o número de limites proposto pelo algoritmo não coincidir com o número de limites esperados para aquela janela de texto. 

Com isso, demonstram em seu trabalho que, em relação a P$_k$, \textit{WindowDiff} consegue resolver seus principais problemas e mantém sua proposta inicial de sensibilidade a \textit{near misses}, penalizando-os menos que os falsos positivos puros.


\end{enumerate}










%nesse exemplo, o valor $0,5$ é substituído por $4$ na matriz de ranks pois há 4 vizinhos com valor inferior
%, o qual é calculado com a Equação~\ref{equ:ranklocal}. 

%o valor $0,5$ é comparado com seus elementos vizinhos, o


%Um exemplo é mostrado na Figura \ref{fig:exemplomatrixrank} abaixo, onde utiliza-se uma máscara de largura igual a 3.



%Por por outro lado, tem a desvantagem de ser mais difícil de interpretar. 
%As medidas apresentadas acima falham ao não serem sensíveis a \textit{near misses}, ou seja, quando um limite não coincide exatamente com o esperado, mas está próximo a ele~\cite{Kern2009}. --> Reescrito por Rafael.



%

% 1 cria uma matrix de similaridades
% 2 cria a matrix de ranking
% 3 aplica divisive clustering

% mask = quadro
% pegar um exemplo --> mostrar os numeros dentro do quatro e pq o resultado foi aquele

% colocar os passos na imagem


%Ela propõe um algoritmo baseado em janelas deslizante, para analisar blocos de texto adjacentes e identificar os limites com base nas similaridades dos blocos.

% baixa complexidade computacional devido a simplicidade do algoritmo e baixa eficiência quando comparado a outros métodos mais sofisticados como apresentados em~\cite{Choi2000, Kern2009, Misra2009}.



% portanto são consideradas candidatas a limite entre segmentos.

% Uma unidade pode ser, por exemplo, palavras, sentenças ou parágrafos devem compartilhar o mesmo assunto.
% que compartilham um assunto. 


%apontam que a coesão léxica é um forte indicador da estrutura do texto, isto é, a mudança de tópicos é acompanhada de uma proporcional mudança de vocabulário. A partir disso, vários algoritmos foram propostos baseados na ideia de que um segmento pode ser identificado e delimitado pela análise das palavras que o compõe~\cite{Galley2003}~\cite{Boguraev2000}.


%\begin{equation}
%r(x,y) = \frac
%{Numero\ de\ elementos\ com\ similaridade\ menor}
%{Numero\ de\ elementos\ examinados}
%\label{equ:ranklocal}
%\end{equation}


% Clustering Reynar maximization
	

%Finalmente, os limites são identificados sempre que a similaridade entre blocos adjacentes entre cada candidato ultrapassa um determinado \textit{threshold}.



% Mensionar que existem duas abordagens principais - Baseada em coesão léxiam e em discursos [ver a pg 2 do Text Segmentation With Topic Moeling and Entity Coherence]

%Essa abordagem apresenta uma redução taxa de erros de 22\% para 10\%. Por outro lado, exige que a quantidade de segmentos seja conhecida.
%Como melhoramento, os autores apresentam posteriormente uma versão do \textit{C99} que utiliza \textit{Latent Semantic Analisys} (LSA) para calcular as similaridades ao invês de cosseno~\cite{Choi2001-LSA}.







%Há ainda outros critérios para segmentação como a segmentação temática 

%outros tipos de abordagem
%	Segmentação funcional
%	Segementação temática


% número de predições corretas com número de total predições

% apresenta um esquema de \textit{rankings} para contornar esse problema.


% As medidas de avaliação tradicionais baseiam se na contagem de acertos. Quando um fim de segmento extraído automaticamente coincide com o limite de referência, têm-se um acerto.

