\section{Referencial Teórico}
	\label{sec:referencial}
	
%%%%%%%%%%
% Retomada das Definições
%%%%%%%%%%	

Um documento textual, sobre tudo quando longo, é frequentemente uma sucessão de tópicos. 
%%%%%%%%%%
% Segmentação
%%%%%%%%%%
A segmentação textual ou segmentação topical é a tarefa de dividir um texto mantendo em cada parte um tópico com seu significado completo.
	
%%%%%%%%%%
% Segmento
%%%%%%%%%%	
Um segmento pode ser visto como uma sucessão de unidades de informação que compartilham um tópico essas unidades podem ser, por exemplo, palavras, sentenças ou parágrafos. Sendo a menor parte de um segmento, portanto são consideradas candidatas a limite entre segmentos.

%%%%%%%%%%
% Coesão léxica como **presuposto básico**
%%%%%%%%%%
Trabalhos anteriores se apoiam na ideia de que a mudança de tópicos em um texto é acompanhada de uma proporcional mudança de vocabulário, essa ideia, chamada de coesão léxica, sugere que a distribuição das palavras é um forte indicador da estrutura do texto. A partir disso, vários algoritmos foram propostos baseados na ideia de que um segmento pode ser identificado e delimitado pela análise das palavras que o compõe~\cite{Galley2003}~\cite{Boguraev2000}.



%, bem como é necessário mensurar suas similaridades. { asunidades de medida}

%%%%%%%%%%
% Porque cosseno
%%%%%%%%%%
Uma vez que a coesão léxica é pressuposto básico da maioria dos algoritmos, o cálculo da similaridade entre unidades de informação (comumente sentenças) é fundamental. Uma medida de similidade frequentemente utilizada é o cosseno, a qual pode ser vista na Equação~\ref{equ:cosine}, sendo $f_{x,j}$ a frequência da palavra $j$ na sentença $x$ e $f_{y,j}$ sendo a frequência da palavra $j$ na sentença $y$.


\begin{equation}
Sim(x,y) = \frac
{\Sigma_j f_{x,j} \times f_{y,j}}
{\sqrt{\Sigma_j f^2_{x,j} \times \Sigma f^2_{y,j}}}
\label{equ:cosine}
\end{equation}


\subsection{Principais algoritmos}
	\label{subsec:principaisalgoritimos}

Entre os principais trabalhos da literatura podemos citar o  \textit{TextTiling}~\cite{Hearst1994} e o \textit{C99}~\cite{Choi2000}, os quais são mostrados a seguir.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%              TextTiling                 %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
O \textit{TextTiling} é um algoritmo baseado em janelas deslizantes, onde para cada candidato a limite, analisa-se o texto circundante. Um limite ou quebra de segmento é identificado quando a similaridade entres os blocos apresenta uma queda considerável.

%Ela propõe um algoritmo baseado em janelas deslizante, para analisar blocos de texto adjacentes e identificar os limites com base nas similaridades dos blocos.

O \textit{TextTiling} recebe uma lista de candidatos a limite, usualmente finais de parágrafo ou finais de sentenças. Para cada posição candidata são construídos 2 blocos, um contendo sentenças que a precedem e outro com as que a sucedem. O tamanho desses blocos é um parâmetro a ser fornecido ao algoritmo e determina o tamanho mínimo de um segmento.
%
Em seguida, os blocos de texto são representados por vetores que contém as frequências de suas palavras. Então, usa-se cosseno (Equação~\ref{equ:cosine}) para calcular a similaridade entre os blocos adjacentes a cada candidato e identifica-se uma transição entre tópicos pelos picos na curva se dissimilaridade.

%TODO como apresentado na Figura~\ref{fig:curvadedissimilaridade}.

%sempre que a similaridade cai abaixo de um \textit{threshold}.

O \textit{TextTiling} apresenta baixa complexidade computacional, devido a simplicidade do algoritmo e baixa eficiência quando comparado a outros métodos mais sofisticados como apresentados em~\cite{Choi2000, Kern2009, Misra2009}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                  C99                    %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Choi \cite{Choi2000} apresenta um esquema de ranking em seu algoritmo, o \textit{C99}. 
%
Embora muitos trabalhos utilizem matrizes de similaridades, o autor traz obervações.
%
Ele aponta que para pequenos segmentos, o cálculo de suas similaridades não é confiável, pois uma ocorrência adicional de uma palavra causa um impacto desproporcional no cálculo.
%
Além disso, o estilo da escrita pode não ser constante em todo o texto. Choi sugere que, por exemplo, textos iniciais dedicados a introdução costumam apresentar menor coesão do que trechos dedicados a um tópico específico. 
%

Portanto, comparar a similaridade entre trechos de diferentes regiões, não é apropriado.
% Complexidade O(n²)
Devido a isso, as similaridades não podem ser comparadas em valores absolutos. Então, o autor apresenta um esquema de \textit{rankings} para contornar esse problema.


%

% 1 cria uma matrix de similaridades
% 2 cria a matrix de ranking
% 3 aplica divisive clustering

% mask = quadro
% pegar um exemplo --> mostrar os numeros dentro do quatro e pq o resultado foi aquele

% colocar os passos na imagem


Inicialmente é construída uma matriz que contém as similaridades de todas as unidades de texto. Em seguida, cada valor na matriz de similaridade é substituído por seu ranking local. Onde para cade elemento da matiz, seu \textit{ranking} é o número de elementos vizinhos com valor de similaridade menor ao seu.%, o qual é calculado com a Equação~\ref{equ:ranklocal}. 

Na Figura~\ref{fig:exemplomatrixrank} vemos um quadro de dimensões 3~x~3 destacado na matriz de similaridades, que contém os valores  $\{0,3; 0,4; 0,4; 0,6; 0,5; 0,2; 0,9; 0,5; 0,7\}$, tomando como exemplo o elemento com valor $0,5$, a mesma posição na matriz de \textit{ranks} terá o valor $4$, pois esse é número de vizinhos com valores inferiores a $0,5$ dentro do quadro analisado na matriz de similaridades. 


%nesse exemplo, o valor $0,5$ é substituído por $4$ na matriz de ranks pois há 4 vizinhos com valor inferior

%o valor $0,5$ é comparado com seus elementos vizinhos, o


%Um exemplo é mostrado na Figura \ref{fig:exemplomatrixrank} abaixo, onde utiliza-se uma máscara de largura igual a 3.



  \begin{figure}[!h]

	\centering
	\includegraphics[width=0.45\textwidth]{exemplo-matrix-rank-noborder.jpg}
	\caption{Exemplo de construção de uma matriz de rank.~\cite{Choi2000}}
	\label{fig:exemplomatrixrank}

  \end{figure}




%\begin{equation}
%r(x,y) = \frac
%{Numero\ de\ elementos\ com\ similaridade\ menor}
%{Numero\ de\ elementos\ examinados}
%\label{equ:ranklocal}
%\end{equation}


% Clustering Reynar maximization
	
Finalmente, utiliza um método de divisão por \textit{clustering} baseado no algoritmo de maximização de Reynar~\cite{Reynar1998} para identificar os limites entre os segmentos. %Essa abordagem apresenta uma redução taxa de erros de 22\% para 10\%. Por outro lado, exige que a quantidade de segmentos seja conhecida.
%Como melhoramento, os autores apresentam posteriormente uma versão do \textit{C99} que utiliza \textit{Latent Semantic Analisys} (LSA) para calcular as similaridades ao invês de cosseno~\cite{Choi2001-LSA}.




\subsection{Medidas de Avaliação}

%%%%%%%%%%
%	Avaliações baseadas em hits 
%%%%%%%%%%

As medidas de avaliação tradicionais, baseiam se na contagem de acertos. No contexto da segmentação de textos um acerto é quando um o limite hipotético coincide com um limite de referência.

Essas medidas de avaliação tentam computar os erros do algoritmo, isto é falsos positivos e falsos negativos, a fim de calcular sua eficiência. 
%
% falso positivo
Um falso positivo é um limite identificado pelo algoritmo que não corresponde a nenhum limite na segmentação de referência. 
%
% falso negativo
Um falso negativo é quando o algoritmo não identifica um limite existente na segmentação de referência.


Nesse sentido, 
%
a precisão, que é a proporção de limites corretamente identificados pelo algoritmo, e 
%
a revocação, que é a proporção de limites verdadeiros que foram identificados pelo algoritmo,
%
trazem alguns problemas na avaliação de segmentadores automáticos.
 	
	
Conforme o algoritmo aponta mais segmentos no texto, este tende a melhorar a revocação e ao mesmo tempo, reduzir a precisão. Esse problema de avaliação pode ser contornado utilizado a medida F-1 que é uma média harmônica entre precisão e revocação onde ambas tem a o mesmo peso. Por por outro lado, tem a desvantagem de ser mais difícil de interpretar. 

As medidas apresentadas acima falham ao não serem sensíveis a \textit{near misses}, ou seja, quando um limite não coincide exatamente com o esperado, mas está próximo a ele~\cite{Kern2009}.

Na Figura~\ref{fig:exemplosegmentacaozoom} é apresentado um exemplo com duas segmentações hipotéticas e uma referência. Na Figura~\ref{fig:exemplosegmentacao}, em ambos os casos não há nenhum verdadeiro positivo, o que implica em zero para os valores de precisão, acurácia, e revocação, embora a segunda hipótese possa ser considerada superior à primeira se levado em conta a proximidade dos limites.



  \begin{figure}[!h]

	\centering
	\includegraphics[width=0.47\textwidth]{windiffzoom.jpg}
	\caption{Exemplos de \textit{near missing} e falso positivo puro. Os blocos indicam uma unidade de informação e as linha verticais representam os limites entre segmentos de texto representando um tópico do texto. }
	\label{fig:exemplosegmentacaozoom}

  \end{figure}
  
  \begin{figure}[!h]

	\centering
	\includegraphics[width=0.47\textwidth]{windiff.jpg}
	\caption{
	Exemplo de duas segmentações hipotéticas em comparação a uma ideal. 
	}
	\label{fig:exemplosegmentacao}

  \end{figure}
  
  
Entre as medidas mais utilizadas para avaliar segmentadores estão:

\begin{enumerate}

	\item P$_k$. A fim de resolver o problema de \textit{near misses}, Beeferman \textit{et. al.}~\cite{Beeferman1999} apresentam uma medida chamada P$_k$ que atribui 
%
valores parciais a \textit{near misses}, 
%
ou seja, limites sempre receberão um peso proporcional à sua proximidade, desde que dentro de um janela de tamanho~$k$.
%
Para isso, esse método move uma janela de tamanho $k$ e a cada posição e verifica se o início e o final da janela estão ou não dentro do mesmo segmento e penaliza o algoritmo em caso de discrepância. Ou seja, dado duas palavras de distancia $k$, uma discrepância é computada quando o algoritmo e a referência não concordam se as palavras estão ou não no mesmo segmento.

O valor de $k$ é calculado como a metade da média dos comprimentos dos segmentos reais. Como resultado, é retornado a contagem de discrepâncias divido pelo quantidade de segmentações analisadas. Esse valor serve como medida de dissimilaridade entre as segmentações e pode ser interpretada como a probabilidade de duas sentenças extraídas aleatoriamente pertencerem ao mesmo segmento.

\item \textit{WindowDiff}. Pevzner~\cite{Pevzner2002} aponta problemas na avaliação mais tradicional, P$_k$~\cite{Beeferman1999}. Eles apontam que esse método penaliza demasiadamente os falsos negativos em relação aos falsos positivos e a \textit{near misses}, além disso, desconsidera o tamanho dos segmentos. Como solução, propõem um método, que traz duas diferenças principais: a dobra da penalidade para os falsos positivos a fim de diminuir o problema da subestimação dessa medida e, diferente de P$_k$, ao mover a janela pelo texto, penaliza-se o algoritmo sempre que o número de limites proposto pelo algoritmo não coincidir com o número de limites esperados para aquela janela de texto. 

Com isso, demonstram em seu trabalho que, em relação a P$_k$, consegue resolver seus principais problemas e mantém sua proposta inicial de sensibilidade a \textit{near misses}, penalizando-os menos que os falsos positivos puros.


\end{enumerate}














%apontam que a coesão léxica é um forte indicador da estrutura do texto, isto é, a mudança de tópicos é acompanhada de uma proporcional mudança de vocabulário. A partir disso, vários algoritmos foram propostos baseados na ideia de que um segmento pode ser identificado e delimitado pela análise das palavras que o compõe~\cite{Galley2003}~\cite{Boguraev2000}.


%Finalmente, os limites são identificados sempre que a similaridade entre blocos adjacentes entre cada candidato ultrapassa um determinado \textit{threshold}.



% Mensionar que existem duas abordagens principais - Baseada em coesão léxiam e em discursos [ver a pg 2 do Text Segmentation With Topic Moeling and Entity Coherence]




%Há ainda outros critérios para segmentação como a segmentação temática 

%outros tipos de abordagem
%	Segmentação funcional
%	Segementação temática
	